{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c796a9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "from numpy.typing import ArrayLike\n",
    "from nn import NeuralNetwork, one_hot_encode_seqs, sample_seqs\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e782a0",
   "metadata": {},
   "source": [
    "### 5-fold CV Grid Search to find optimal learning rate and activation function hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "316ff326",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "digits = datasets.load_digits()\n",
    "X = digits['data']\n",
    "y = digits['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "# perform Grid search via cross validation on the training data  \n",
    "#training data will be split into train and validation set, while the original \n",
    "#test set is held out\n",
    "\n",
    "#saving the average MSE across all epochs in each fold with each combination of proposed\n",
    "#hyperparameters\n",
    "columns = [\"lr\",\"activation_layer1\",\"activation_layer2\",\"avg_train_error\",\"avg_val_error\"] + [f\"train_error_fold_{x}\" for x in range(1,6)] \\\n",
    "         + [f\"val_error_fold_{x}\" for x in range(1,6)]            \n",
    "tuning_results_df = pd.DataFrame(columns = columns)\n",
    "lrs = [0.01,0.001,0.0001]\n",
    "activations = ['relu','sigmoid']                                              \n",
    "kf = KFold(n_splits=5)\n",
    "df_idx = 0\n",
    "for lr in lrs:\n",
    "    for activation_layer1 in activations:\n",
    "        for activation_layer2 in activations:\n",
    "            fold_avg_train_losses = []\n",
    "            fold_avg_val_losses = []\n",
    "            for fold_idx, (train,val) in enumerate(kf.split(X_train,y_train)):\n",
    "                fold_idx = fold_idx + 1\n",
    "                nn = NeuralNetwork(nn_arch=[{'input_dim': 64, 'output_dim': 16, 'activation': activation_layer1},\n",
    "                               {'input_dim': 16, 'output_dim': 64, 'activation': activation_layer2}],\n",
    "                               lr=lr, batch_size=200, seed=42, epochs=10, loss_function=\n",
    "                               'mean_squared_error') \n",
    "                #fit this fold. test data is still held out\n",
    "                train_loss, val_loss = nn.fit(X_train[train],y_train[train],\n",
    "                                               X_train[val],y_train[val])\n",
    "                fold_avg_train_loss = np.mean(train_loss) #avg (across epochs) training loss for this fold\n",
    "                fold_avg_train_losses.append(fold_avg_train_loss)\n",
    "\n",
    "                fold_avg_val_loss = np.mean(val_loss) #avg (across epochs) validation loss for this fold\n",
    "                fold_avg_val_losses.append(fold_avg_val_loss)\n",
    "\n",
    "\n",
    "                #store hyperparameters and per-fold results\n",
    "                tuning_results_df.loc[df_idx,\"lr\"] = lr\n",
    "                tuning_results_df.loc[df_idx,\"activation_layer1\"] = activation_layer1\n",
    "                tuning_results_df.loc[df_idx,\"activation_layer2\"] = activation_layer2\n",
    "                tuning_results_df.loc[df_idx,f\"train_error_fold_{fold_idx}\"] = fold_avg_train_loss\n",
    "                tuning_results_df.loc[df_idx,f\"val_error_fold_{fold_idx}\"] = fold_avg_val_loss\n",
    "\n",
    "            #store average train and val loss across all folds for this combination of hyperparameters\n",
    "            tuning_results_df.loc[df_idx,\"avg_train_error\"] = np.mean(fold_avg_train_losses)\n",
    "            tuning_results_df.loc[df_idx,\"avg_val_error\"] = np.mean(fold_avg_val_losses)\n",
    "\n",
    "            df_idx +=1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3b8709a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>activation_layer1</th>\n",
       "      <th>activation_layer2</th>\n",
       "      <th>avg_train_error</th>\n",
       "      <th>avg_val_error</th>\n",
       "      <th>train_error_fold_1</th>\n",
       "      <th>train_error_fold_2</th>\n",
       "      <th>train_error_fold_3</th>\n",
       "      <th>train_error_fold_4</th>\n",
       "      <th>train_error_fold_5</th>\n",
       "      <th>val_error_fold_1</th>\n",
       "      <th>val_error_fold_2</th>\n",
       "      <th>val_error_fold_3</th>\n",
       "      <th>val_error_fold_4</th>\n",
       "      <th>val_error_fold_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>113.150165</td>\n",
       "      <td>114.578386</td>\n",
       "      <td>121.670254</td>\n",
       "      <td>127.487691</td>\n",
       "      <td>122.197475</td>\n",
       "      <td>107.624347</td>\n",
       "      <td>86.771059</td>\n",
       "      <td>123.61386</td>\n",
       "      <td>127.863017</td>\n",
       "      <td>126.388067</td>\n",
       "      <td>107.92406</td>\n",
       "      <td>87.102928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>relu</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>10.055893</td>\n",
       "      <td>10.015503</td>\n",
       "      <td>10.201856</td>\n",
       "      <td>9.932672</td>\n",
       "      <td>9.934994</td>\n",
       "      <td>10.047938</td>\n",
       "      <td>10.162005</td>\n",
       "      <td>9.43516</td>\n",
       "      <td>10.518739</td>\n",
       "      <td>10.491444</td>\n",
       "      <td>10.052157</td>\n",
       "      <td>9.580014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>6.58857</td>\n",
       "      <td>6.397731</td>\n",
       "      <td>6.65632</td>\n",
       "      <td>6.63471</td>\n",
       "      <td>6.467627</td>\n",
       "      <td>6.517218</td>\n",
       "      <td>6.666977</td>\n",
       "      <td>6.013618</td>\n",
       "      <td>6.50747</td>\n",
       "      <td>6.667328</td>\n",
       "      <td>6.432185</td>\n",
       "      <td>6.368055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>10.65468</td>\n",
       "      <td>10.61597</td>\n",
       "      <td>10.801299</td>\n",
       "      <td>10.52556</td>\n",
       "      <td>10.533753</td>\n",
       "      <td>10.646487</td>\n",
       "      <td>10.766301</td>\n",
       "      <td>10.014267</td>\n",
       "      <td>11.161487</td>\n",
       "      <td>11.108588</td>\n",
       "      <td>10.64613</td>\n",
       "      <td>10.149377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>9.514819</td>\n",
       "      <td>9.554559</td>\n",
       "      <td>10.166983</td>\n",
       "      <td>9.273173</td>\n",
       "      <td>9.692863</td>\n",
       "      <td>8.846406</td>\n",
       "      <td>9.594669</td>\n",
       "      <td>9.481094</td>\n",
       "      <td>9.57218</td>\n",
       "      <td>10.197213</td>\n",
       "      <td>8.980242</td>\n",
       "      <td>9.542063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>10.377542</td>\n",
       "      <td>10.342087</td>\n",
       "      <td>10.524567</td>\n",
       "      <td>10.251978</td>\n",
       "      <td>10.254259</td>\n",
       "      <td>10.372322</td>\n",
       "      <td>10.484585</td>\n",
       "      <td>9.751161</td>\n",
       "      <td>10.868399</td>\n",
       "      <td>10.825495</td>\n",
       "      <td>10.378314</td>\n",
       "      <td>9.887066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>10.730312</td>\n",
       "      <td>10.612039</td>\n",
       "      <td>10.864556</td>\n",
       "      <td>10.625455</td>\n",
       "      <td>10.615023</td>\n",
       "      <td>10.714173</td>\n",
       "      <td>10.832355</td>\n",
       "      <td>10.004383</td>\n",
       "      <td>11.161976</td>\n",
       "      <td>11.10428</td>\n",
       "      <td>10.637897</td>\n",
       "      <td>10.15166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>11.561338</td>\n",
       "      <td>11.550595</td>\n",
       "      <td>11.715675</td>\n",
       "      <td>11.415269</td>\n",
       "      <td>11.435016</td>\n",
       "      <td>11.555211</td>\n",
       "      <td>11.685518</td>\n",
       "      <td>10.923923</td>\n",
       "      <td>12.147452</td>\n",
       "      <td>12.061213</td>\n",
       "      <td>11.575066</td>\n",
       "      <td>11.045319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>7.266413</td>\n",
       "      <td>7.160278</td>\n",
       "      <td>7.354888</td>\n",
       "      <td>7.280636</td>\n",
       "      <td>7.164199</td>\n",
       "      <td>7.253355</td>\n",
       "      <td>7.278986</td>\n",
       "      <td>6.784221</td>\n",
       "      <td>7.192272</td>\n",
       "      <td>7.61485</td>\n",
       "      <td>7.176034</td>\n",
       "      <td>7.034016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>relu</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>11.189513</td>\n",
       "      <td>11.171741</td>\n",
       "      <td>11.341502</td>\n",
       "      <td>11.052267</td>\n",
       "      <td>11.064665</td>\n",
       "      <td>11.182303</td>\n",
       "      <td>11.306828</td>\n",
       "      <td>10.551534</td>\n",
       "      <td>11.739686</td>\n",
       "      <td>11.681187</td>\n",
       "      <td>11.199161</td>\n",
       "      <td>10.687137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>relu</td>\n",
       "      <td>13.038375</td>\n",
       "      <td>13.024587</td>\n",
       "      <td>13.202417</td>\n",
       "      <td>12.872742</td>\n",
       "      <td>12.905531</td>\n",
       "      <td>13.034947</td>\n",
       "      <td>13.176235</td>\n",
       "      <td>12.356365</td>\n",
       "      <td>13.701759</td>\n",
       "      <td>13.564476</td>\n",
       "      <td>13.03875</td>\n",
       "      <td>12.461583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>11.741482</td>\n",
       "      <td>11.739977</td>\n",
       "      <td>11.899066</td>\n",
       "      <td>11.590075</td>\n",
       "      <td>11.613021</td>\n",
       "      <td>11.736057</td>\n",
       "      <td>11.869193</td>\n",
       "      <td>11.108262</td>\n",
       "      <td>12.345373</td>\n",
       "      <td>12.25414</td>\n",
       "      <td>11.763231</td>\n",
       "      <td>11.228881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lr activation_layer1 activation_layer2 avg_train_error avg_val_error  \\\n",
       "0     0.01              relu              relu      113.150165    114.578386   \n",
       "1     0.01              relu           sigmoid       10.055893     10.015503   \n",
       "2     0.01           sigmoid              relu         6.58857      6.397731   \n",
       "3     0.01           sigmoid           sigmoid        10.65468      10.61597   \n",
       "4    0.001              relu              relu        9.514819      9.554559   \n",
       "5    0.001              relu           sigmoid       10.377542     10.342087   \n",
       "6    0.001           sigmoid              relu       10.730312     10.612039   \n",
       "7    0.001           sigmoid           sigmoid       11.561338     11.550595   \n",
       "8   0.0001              relu              relu        7.266413      7.160278   \n",
       "9   0.0001              relu           sigmoid       11.189513     11.171741   \n",
       "10  0.0001           sigmoid              relu       13.038375     13.024587   \n",
       "11  0.0001           sigmoid           sigmoid       11.741482     11.739977   \n",
       "\n",
       "   train_error_fold_1 train_error_fold_2 train_error_fold_3  \\\n",
       "0          121.670254         127.487691         122.197475   \n",
       "1           10.201856           9.932672           9.934994   \n",
       "2             6.65632            6.63471           6.467627   \n",
       "3           10.801299           10.52556          10.533753   \n",
       "4           10.166983           9.273173           9.692863   \n",
       "5           10.524567          10.251978          10.254259   \n",
       "6           10.864556          10.625455          10.615023   \n",
       "7           11.715675          11.415269          11.435016   \n",
       "8            7.354888           7.280636           7.164199   \n",
       "9           11.341502          11.052267          11.064665   \n",
       "10          13.202417          12.872742          12.905531   \n",
       "11          11.899066          11.590075          11.613021   \n",
       "\n",
       "   train_error_fold_4 train_error_fold_5 val_error_fold_1 val_error_fold_2  \\\n",
       "0          107.624347          86.771059        123.61386       127.863017   \n",
       "1           10.047938          10.162005          9.43516        10.518739   \n",
       "2            6.517218           6.666977         6.013618          6.50747   \n",
       "3           10.646487          10.766301        10.014267        11.161487   \n",
       "4            8.846406           9.594669         9.481094          9.57218   \n",
       "5           10.372322          10.484585         9.751161        10.868399   \n",
       "6           10.714173          10.832355        10.004383        11.161976   \n",
       "7           11.555211          11.685518        10.923923        12.147452   \n",
       "8            7.253355           7.278986         6.784221         7.192272   \n",
       "9           11.182303          11.306828        10.551534        11.739686   \n",
       "10          13.034947          13.176235        12.356365        13.701759   \n",
       "11          11.736057          11.869193        11.108262        12.345373   \n",
       "\n",
       "   val_error_fold_3 val_error_fold_4 val_error_fold_5  \n",
       "0        126.388067        107.92406        87.102928  \n",
       "1         10.491444        10.052157         9.580014  \n",
       "2          6.667328         6.432185         6.368055  \n",
       "3         11.108588         10.64613        10.149377  \n",
       "4         10.197213         8.980242         9.542063  \n",
       "5         10.825495        10.378314         9.887066  \n",
       "6          11.10428        10.637897         10.15166  \n",
       "7         12.061213        11.575066        11.045319  \n",
       "8           7.61485         7.176034         7.034016  \n",
       "9         11.681187        11.199161        10.687137  \n",
       "10        13.564476         13.03875        12.461583  \n",
       "11         12.25414        11.763231        11.228881  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#resulting dataframe stores error from each fold with each combination of hyperparameters\n",
    "#as well as the average error across all 5 folds with each combnation of hyperparameters\n",
    "display(tuning_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03c4b730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lr                        0.01\n",
       "activation_layer1      sigmoid\n",
       "activation_layer2         relu\n",
       "avg_train_error        6.58857\n",
       "avg_val_error         6.397731\n",
       "train_error_fold_1     6.65632\n",
       "train_error_fold_2     6.63471\n",
       "train_error_fold_3    6.467627\n",
       "train_error_fold_4    6.517218\n",
       "train_error_fold_5    6.666977\n",
       "val_error_fold_1      6.013618\n",
       "val_error_fold_2       6.50747\n",
       "val_error_fold_3      6.667328\n",
       "val_error_fold_4      6.432185\n",
       "val_error_fold_5      6.368055\n",
       "Name: 2, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal learning rate was 0.01\n",
      "The optimal activation function to use in layer 1 was sigmoid\n",
      "The optimal activation function to use in layer 2 was relu\n"
     ]
    }
   ],
   "source": [
    "#get data for combination of hyperparameters that gave the lowest average MSE\n",
    "# across epochs and folds in the validation set\n",
    "display(tuning_results_df.loc[tuning_results_df['avg_val_error'].astype(float).idxmin()])\n",
    "best_lr = tuning_results_df.loc[tuning_results_df['avg_val_error'].astype(float).idxmin(),'lr']\n",
    "best_activation_layer1 = tuning_results_df.loc[tuning_results_df['avg_val_error'].astype(float).idxmin(),'activation_layer1']\n",
    "best_activation_layer2 = tuning_results_df.loc[tuning_results_df['avg_val_error'].astype(float).idxmin(),'activation_layer2']\n",
    "\n",
    "print(f\"The optimal learning rate was {best_lr}\")\n",
    "print(f\"The optimal activation function to use in layer 1 was {best_activation_layer1}\")\n",
    "print(f\"The optimal activation function to use in layer 2 was {best_activation_layer2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299df244",
   "metadata": {},
   "source": [
    "#### Re-training model with optimal set of hyperparameters and plotting per-epoch train and test MSE\n",
    "\n",
    "* I chose learning rate and activation function (for each layer) hyperparameters by implementing a cross-validated grid search; the hyperparameters that minimized the average across-fold MSE on the test set were used moving forward. A subset of samples were completely held out from this procedure to be used for validation/testing here. \n",
    "* These results suggest the model was able to learn from the training data and properly generalize to the unseen  data, as the unseen validation loss decreased over the epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "631ab202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAI4CAYAAABndZP2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABLeElEQVR4nO3dd3xc9Z3v//dnZtSLmyRbcsE2NgZjSxRDKKEaEkAWSTb3JmEDm80ml03vN5vd391N7t7c329zNze9LSmkEbIbUjbYhN4TmoG4YcAdGxfJVc2q8/n9MUf2WFYZSxqdmdHr+XjMY86cOXPOR0ysvPX9fM855u4CAADIJZGwCwAAABhrBBwAAJBzCDgAACDnEHAAAEDOIeAAAICcQ8ABAAA5h4ADIDRm9j0z+8ew6wCQewg4QI4zs+1mdk0Ix/2xmX2x37q5ZuZmFpMkd/+Au/+vFPYVys8AIHsRcADktL4wBWBiIeAAE5SZFZjZ18xsd/D4mpkVBO9VmNlKMztsZgfN7AkziwTv/Z2ZvW5mLWb2ipktH0UNx0Z5Bjummf1M0hxJd5tZq5l9Ntj+RjPbEGz/qJmdlbTf7UGdayW1mdl/N7Nf9zv2N83sayOtHUBm4y8bYOL6fyRdJOkcSS7pPyX9D0n/KOnTknZJqgy2vUiSm9kiSR+RdIG77zazuZKiY1TPgMd091vM7DJJ73f3ByXJzM6QdKekt0p6VNInlQhAi929K/j8TZLqJe2XNFnSF8xssrsfDkZ13inp+jGqHUCGYQQHmLjeLemf3b3R3Zsk/U9JtwTvdUuqlnSau3e7+xOeuHFdr6QCSYvNLM/dt7v7liGO8ZlghOWwmR2WtHaIbQc75kDeKWmVuz/g7t2SviypSNIlSdt8w913uvtRd98j6XFJ/zV47zpJ+939+SHqAZDFCDjAxFUjaUfS6x3BOkn6V0mbJd1vZlvN7HOS5O6bJX1C0hckNZrZL82sRoP7srtP7ntIqh1i2wGPmUrt7h6XtFPSzKRtdvb7zE8k3Rws3yzpZ0PsH0CWI+AAE9duSaclvZ4TrJO7t7j7p919vqQGSZ/qm2vj7r9w9zcGn3VJXxqLYoY6ZnCcQWs3M5M0W9Lrybvs95nfSao1syWSVki6YyzqBpCZCDjAxJBnZoVJj5gSc1j+h5lVmlmFpH+S9HNJMrMVZrYgCA7NSrSmes1skZldHUxG7pB0NHhv1AY7ZvD2Pknzkzb/D0n1ZrbczPKUmL/TKelPg+3f3Tsk3SXpF5KedffXxqJuAJmJgANMDPcoEUb6Hl+Q9EVJq5WYF7NO0gvBOklaKOlBSa2SnpL0HXd/VIn5N/+ixMTdvZKqJP3DGNU42DEl6f9TIowdNrPPuPsrSrSZvhnU0iCpIWmC8WB+ImmpaE8BOc8Gn8MHALnFzOZIelnSDHdvDrseAOnDCA6ACSG4js+nJP2ScAPkPq6DAyDnmVmJEvN4dihxijiAHEeLCgAA5BxaVAAAIOcQcAAAQM4h4AAAgJxDwAEAADmHgAMAAHIOAQcAAOQcAg4AAMg5BBwAAJBzCDgAACDnEHAApJWZ/cHM3jPW2wLAULhVA4CTmFlr0stiSZ2SeoPXf+vud4x/VSNnZldK+rm7zwq5FADjhJttAjiJu5f2LZvZdknvd/cH+29nZjF37xnP2gAgFbSoAKTMzK40s11m9ndmtlfS7WY2xcxWmlmTmR0KlmclfeZRM3t/sPzXZvakmX052HabmV0/wm3nmdnjZtZiZg+a2bfN7Ocj+JnOCo572Mw2mNmNSe/dYGYvBcd43cw+E6yvCH7Ow2Z20MyeMDN+nwIZhH+QAE7VDElTJZ0m6VYlfo/cHryeI+mopG8N8fk3SHpFUoWk/yPph2ZmI9j2F5KelTRN0hck3XKqP4iZ5Um6W9L9kqokfVTSHWa2KNjkh0q05MokLZH0cLD+05J2SaqUNF3SP0ii3w9kEAIOgFMVl/R5d+9096PufsDdf+3u7e7eIul/S7piiM/vcPfvu3uvpJ9IqlYiJKS8rZnNkXSBpH9y9y53f1LS70fws1wkqVTSvwT7eVjSSkk3Be93S1psZuXufsjdX0haXy3pNHfvdvcnnAmNQEYh4AA4VU3u3tH3wsyKzezfzGyHmTVLelzSZDOLDvL5vX0L7t4eLJae4rY1kg4mrZOknaf4cyjYz053jyet2yFpZrD8dkk3SNphZo+Z2cXB+n+VtFnS/Wa21cw+N4JjA0gjAg6AU9V/pOLTkhZJeoO7l0u6PFg/WNtpLOyRNNXMipPWzR7BfnZLmt1v/swcSa9Lkrs/5+5vUaJ99TtJ/xGsb3H3T7v7fEkNkj5lZstHcHwAaULAATBaZUrMuzlsZlMlfT7dB3T3HZJWS/qCmeUHIysNw33OzAqTH0rM4WmT9FkzywtOJ2+Q9Mtgv+82s0nu3i2pWcGp8ma2wswWBPOB+tb3DnRMAOEg4AAYra9JKpK0X9LTku4dp+O+W9LFkg5I+qKkf1fiej2DmalEEEt+zJZ0o6Trlaj/O5L+yt1fDj5zi6TtQevtA5JuDtYvlPSgpFZJT0n6jrs/OlY/GIDR40J/AHKCmf27pJfdPe0jSAAyHyM4ALKSmV1gZqebWcTMrpP0FiXmyQAAVzIGkLVmSPqNEtfB2SXpg+7+YrglAcgUtKgAAEDOoUUFAAByDgEHAADknKyYg1NRUeFz584NuwwAAJBhnn/++f3uXtl/fVYEnLlz52r16tVhlwEAADKMme0YaD0tKgAAkHMIOAAAIOcQcAAAQM4h4AAAgJxDwAEAADmHgAMAAHIOAQcAAOScCR1w9jV36J/vfkmb9rWEXQoAABhDEzrgRMz04z9t091rdoddCgAAGEMTOuBUlhXoovnTtHLdHnFXdQAAcseEDjiSVF9bra1NbXp5L20qAAByxYQPONedPUMRk1at3RN2KQAAYIxM+IAzrbRAF58+TatoUwEAkDMmfMCRpPqlNdq2v00b99CmAgAgFxBwJL357OmKRkyr1nE2FQAAuYCAo0Sb6pLTp2nVWtpUAADkAgJOoH5ptbYfaNeG3c1hlwIAAEaJgBN489kzgjYVZ1MBAJDtCDiBKSX5uuT0abqHs6kAAMh6BJwkK2qrtYM2FQAAWY+Ak+RNi2coFjGt5KJ/AABkNQJOkikl+bp0QYVWrdtNmwoAgCyWtoBjZj8ys0YzW5+0bqqZPWBmm4LnKek6/kjV11Zr58GjWvf6kbBLAQAAI5TOEZwfS7qu37rPSXrI3RdKeih4nVHevHiG8qLGvakAAMhiaQs47v64pIP9Vr9F0k+C5Z9Iemu6jj9Sk4rzgjYVZ1MBAJCtxnsOznR33yNJwXPVOB8/JfVLq7Xr0FGt3UWbCgCAbJSxk4zN7FYzW21mq5uamsb12G/qa1Nx0T8AALLSeAecfWZWLUnBc+NgG7r7be6+zN2XVVZWjluBUqJNddnCSu5NBQBAlhrvgPN7Se8Jlt8j6T/H+fgpq19ardcPH9Wfdx4OuxQAAHCK0nma+J2SnpK0yMx2mdn7JP2LpGvNbJOka4PXGemaxdOVH41wNhUAAFkolq4du/tNg7y1PF3HHEuTivJ02cIK3bNuj/6f+rNkZmGXBAAAUpSxk4wzQX1ttXYf6dCLtKkAAMgqBJwh0KYCACA7EXCGUF6Yp8vPqNQ96/YoHudsKgAAsgUBZxgraqu150iHXtx5KOxSAABAigg4w1h+VpXyYxGtpE0FAEDWIOAMo6wwT1ecUak/rNtLmwoAgCxBwEnBitpq7W3u0Auv0aYCACAbEHBSsPys6bSpAADIIgScFJQWxHTVIs6mAgAgWxBwUlRfW6PGlk6t3kGbCgCATEfASdHyM6tUEIto1drdYZcCAACGQcBJUUlBTFctqtIf1u9VL20qAAAyGgHnFNTXVifaVNsPhl0KAAAYAgHnFFx9ZpUK8yJatY6zqQAAyGQEnFNQUhDT1WdW6Z51tKkAAMhkBJxTVL+0RvtbO/XsNtpUAABkKgLOKbrqzMqgTcXZVAAAZCoCzikqzo9p+ZnTdS9nUwEAkLEIOCNQX1ut/a1dembbgbBLAQAAAyDgjMBVi6pUlBfVKu5NBQBARiLgjEBRflTLz6rSvev3qqc3HnY5AACgHwLOCK2ordaBti49w9lUAABkHALOCF25qErF+VGtpE0FAEDGIeCMUGFeVMvPmq77NtCmAgAg0xBwRqF+abUOtnXp6a20qQAAyCQEnFG4clGlSvKjXPQPAIAMQ8AZhcK8qK5ZnLjoXzdtKgAAMgYBZ5Tql1brUHu3ntrCRf8AAMgUBJxRuvyMSpUWxLjoHwAAGYSAM0qFeVFdc1aV7nuJNhUAAJmCgDMG6mtrdLi9W3+iTQUAQEYIJeCY2cfNbL2ZbTCzT4RRw1i6bGGFygpiWrWWs6kAAMgE4x5wzGyJpP8m6UJJdZJWmNnC8a5jLBXmRXXt4um6b8M+dfXQpgIAIGxhjOCcJelpd2939x5Jj0l6Wwh1jKn62modOdqtP27ZH3YpAABMeGEEnPWSLjezaWZWLOkGSbNDqGNMvTFoU93D2VQAAIRu3AOOu2+U9CVJD0i6V9IaST39tzOzW81stZmtbmpqGucqT11BLKprz07cm4o2FQAA4QplkrG7/9Ddz3P3yyUdlLRpgG1uc/dl7r6ssrJy/IscgRW11Wru6NEfN9OmAgAgTGGdRVUVPM+R9BeS7gyjjrH2xgWVKiuMaSVtKgAAQhUL6bi/NrNpkrolfdjdD4VUx5jKj0X05rNn6L4Ne9XZs0QFsWjYJQEAMCGF1aK6zN0Xu3uduz8URg3pUr+0Wi0dPXpyE20qAADCwpWMx9ilCypUXhjTqnW0qQAACAsBZ4z1take2LBPnT29YZcDAMCERMBJg/raarV09uiJV2lTAQAQBgJOGly6oEKTivJoUwEAEBICThrkRSO67uwZeuClferopk0FAMB4I+CkyQ211Wrt7NHjr2b+VZgBAMg1BJw0ueT0aZpcnKd7aFMBADDuCDhpQpsKAIDwEHDSqL62Wm1dvXqMNhUAAOOKgJNGF8+fpinFeVrFvakAABhXBJw0ikUjum5JtR7cSJsKAIDxRMBJs/ql1Wrv6tWjrzSGXQoAABMGASfNLpo/VVNL8rVq3d6wSwEAYMIg4KRZok01Qw9t3KejXbSpAAAYD8MGHDM73cwKguUrzexjZjY57ZXlkBW0qQAAGFepjOD8WlKvmS2Q9ENJ8yT9Iq1V5ZgL501VRWm+VnLRPwAAxkUqASfu7j2S3ibpa+7+SUnV6S0rt/S1qR7e2Kj2rp6wywEAIOelEnC6zewmSe+RtDJYl5e+knLTDUurdbS7V4+8zEX/AABIt1QCznslXSzpf7v7NjObJ+nn6S0r97xh3jRVlOZzbyoAAMZBbLgN3P0lSR+TJDObIqnM3f8l3YXlmmjEdP2Sav3q+Z1q7+pRcf6w/+kBAMAIpXIW1aNmVm5mUyWtkXS7mX0l/aXlnvraanV0x/Xwy5xNBQBAOqXSoprk7s2S/kLS7e5+vqRr0ltWbrpg7lRVlhVwbyoAANIslYATM7NqSe/Q8UnGGIFoxHTDkhl6+OVGtXVyNhUAAOmSSsD5Z0n3Sdri7s+Z2XxJm9JbVu66YWm1Onvieog2FQAAaTNswHH3X7l7rbt/MHi91d3fnv7SctOyuVNVVVage2hTAQCQNqlMMp5lZr81s0Yz22dmvzazWeNRXC6KRkw3LK3WI680qpU2FQAAaZFKi+p2Sb+XVCNppqS7g3UYofraoE21cV/YpQAAkJNSCTiV7n67u/cEjx9LqkxzXTnt/DlTNL2cs6kAAEiXVALOfjO72cyiweNmSQfSXVguiwRtqkdfbVJLR3fY5QAAkHNSCTh/o8Qp4nsl7ZH0X5S4fQNGoX5ptbp64npoI2dTAQAw1lI5i+o1d7/R3Svdvcrd36rg1g0YufPmTNGM8kKt4t5UAACMuVRGcAbyjjGtYgLqa1M99gptKgAAxtpIA46N5qBm9kkz22Bm683sTjMrHM3+slV9bbW6euN6kLOpAAAYU4MGHDObOshjmkYRcMxsphItrmXuvkRSVNK7Rrq/bHbu7MmqmVTI2VQAAIyx2BDvPS/JNXCY6RqD4xaZWbekYkm7R7m/rBSJmK5fWq2fPbVDzR3dKi/MC7skAABywqAjOO4+z93nB8/9H/NHekB3f13SlyW9psRZWUfc/f6R7i/bHWtTvUSbCgCAsTLSOTgjZmZTJL1F0jwlro5cElxbp/92t5rZajNb3dTUNN5ljptzZ0/WzMlFtKkAABhD4x5wJF0jaZu7N7l7t6TfSLqk/0bufpu7L3P3ZZWVuXvhZDPTDUtn6PFNTTpylLOpAAAYC2EEnNckXWRmxWZmkpZL2hhCHRmjvrZG3b2uB2hTAQAwJlIKOMEtGmrMbE7fY6QHdPdnJN0l6QVJ64Iabhvp/nJB3axJQZtqQs61BgBgzA11FpUkycw+KunzkvZJigerXVLtSA/q7p8P9gkl2lT1tdW6/Y/bdKS9W5OKOZsKAIDRSGUE5+OSFrn72e6+NHiMONxgYPVLq9Xd67r/pb1hlwIAQNZLJeDslHQk3YVMdLWzJmnWlCLuTQUAwBgYtkUlaaukR81slaTOvpXu/pW0VTUB9bWpfvjENh1u79Lk4vywSwIAIGulMoLzmqQHJOVLKkt6YIytWFqjnrjr/g2cTQUAwGgMO4Lj7v9zPAqBtGRmueZMLdbKdXv0jgtmh10OAABZa9CAY2Zfc/dPmNndSpw1dQJ3vzGtlU1AiYv+Vev7T2zVobYuTSmhTQUAwEgMNYLzs+D5y+NRCBJW1Fbre49t0f0v7dU7Lxjx5YYAAJjQBg047v588PzY+JWDs2vKddq0Yq1cu4eAAwDACA07ydjMFprZXWb2kplt7XuMR3ETkZmpfmm1/rTlgA62dYVdDgAAWSmVs6hul/RdST2SrpL0Ux1vXyEN6mur1Rt33beBi/4BADASqQScInd/SJK5+w53/4Kkq9Nb1sS2uLpc8ypKtGotF/0DAGAkUgk4HWYWkbTJzD5iZm+TVJXmuia0xNlUM/SnLft1oLVz+A8AAIATpBJwPiGpWNLHJJ0v6WZJ70ljTZBUv7RGcZfu46J/AACcsiEDjplFJb3D3VvdfZe7v9fd3+7uT49TfRPWWdVlml9RolXrdoddCgAAWWfQgGNmMXfvlXS+mdk41gQdvzfVU1sOaD9tKgAATslQIzjPBs8vSvpPM7vFzP6i7zEOtU149bXVirt073rOpgIA4FSkMgdnqqQDSpw5tUJSQ/CMNFs0vUynV3I2FQAAp2qoWzVUmdmnJK1X4l5UyW2qk+5NhbHXd9G/bz2yWU0tnaosKwi7JAAAssJQIzhRSaXBoyxpue+BcVBfmzib6l4u+gcAQMqGGsHZ4+7/PG6VYEBnTC/VgqpSrVq7W7dcdFrY5QAAkBWGGsHhzKkM0NemembbQTW2dIRdDgAAWWGogLN83KrAkOprq+WcTQUAQMoGDTjufnA8C8HgzphepjOml2olZ1MBAJCSVE4TRwa4YWm1ntt+UI3NtKkAABgOASdL1C9NtKn+QJsKAIBhEXCyxMLpZVo0vYyL/gEAkAICThapr63WczsOau8R2lQAAAyFgJNFbjjWpmIUBwCAoRBwssiCqlKdOYM2FQAAwyHgZJn6pdVaveOQ9hw5GnYpAABkLAJOlrmhtlqS9Id1nE0FAMBgxj3gmNkiM/tz0qPZzD4x3nVkq9MrS3VWdblWraNNBQDAYMY94Lj7K+5+jrufI+l8Se2SfjvedWSzFbXVen7HIe0+TJsKAICBhN2iWi5pi7vvCLmOrHLD0kSb6h5GcQAAGFDYAeddku4MuYasM6+iRItpUwEAMKjQAo6Z5Uu6UdKvBnn/VjNbbWarm5qaxre4LFBfW60XXzus12lTAQBwkjBHcK6X9IK77xvoTXe/zd2XufuyysrKcS4t89Uv7TubilEcAAD6CzPg3CTaUyM2t6JES2aWayUX/QMA4CShBBwzK5Z0raTfhHH8XFG/tEZ/3nlYOw+2h10KAAAZJZSA4+7t7j7N3Y+EcfxccaxNxb2pAAA4QdhnUWEU5kwr1tKZk7g3FQAA/RBwslx9bbXW7DpCmwoAgCQEnCxXz0X/AAA4CQEny82eWqy6WZO46B8AAEkIODmgvrZaa3cd0WsHaFMBACARcHJC372pGMUBACCBgJMDZk0pVt3syVq1bnfYpQAAkBEIODlixdJqrX+9WTsOtIVdCgAAoSPg5Ijrl86QRJsKAACJgJMzZk0p1rlzJnPRPwAARMDJKfVLq7Vhd7O27adNBQCY2Ag4OeQGLvoHAIAkAk5OqZlcpPPmTNavVu/U1qbWsMsBACA0BJwc88ErF2hfc6eu+cpj+vR/rOGsKgDAhETAyTHXLp6uxz97lf7m0nlauXa3rv6/j+nv7lrLzTgBABOKuXvYNQxr2bJlvnr16rDLyDqNzR36zqNb9ItnXlPcXe+4YLY+ctUC1UwuCrs0AADGhJk97+7LTlpPwMl9e44c1Xce2aJfPveaTKZ3XThbH7pygWZMKgy7NAAARoWAA+061K5vP7JFv1q9U5GI6d1vmKMPXnm6qsoIOgCA7ETAwTE7D7brmw9v0q9feF15UdMtF52mv73idFWUFoRdGgAAp4SAg5Ns29+mbz60Sb/78+sqiEX1nkvm6tbL52tqSX7YpQEAkBICDga1ubFV33hok+5eu1vFeVG999J5ev9l8zS5mKADAMhsBBwM69V9Lfr6g5u0at0elRXE9L7L5ulv3jhP5YV5YZcGAMCACDhI2cY9zfr6g5t074a9Ki+M6dbL5+uvL52n0oJY2KUBAHACAg5O2frXj+hrD27Sgxv3aXJxnv728tP1VxefphKCDgAgQxBwMGJrdh7W1x58VY+80qRpJfn6wBWn6+aLTlNRfjTs0gAAExwBB6P2wmuH9NUHXtUTm/arorRAH7rydP3lG+aoMI+gAwAIBwEHY+a57Qf11Qde1Z+2HND08gJ9+KoFeucFs1UQI+gAAMYXAQdj7qktB/TVB17Vs9sPqnpSoT5y9QL91/NnKz/GPVwBAOODgIO0cHf9cfMBfeWBV/TCa4c1c3KRPrZ8gf7ivFnKixJ0AADpRcBBWrm7Hnu1SV994FWt2XVEc6YW62PLF+qt59QoRtABAKQJAQfjwt318MuN+soDr2rD7mbNqyjRx5cvVENdjaIRC7s8AECOGSzghPKntZlNNrO7zOxlM9toZheHUQfGnplp+VnTtfKjb9S/3XK+CmIRfeLf/6w3ffUx3b1mt+LxzA/UAIDsF1bv4OuS7nX3MyXVSdoYUh1IEzPTm8+eoXs+dpm+8+7zFDHTR+98Udd//Qn9Yd0egg4AIK3GvUVlZuWS1kia7ykenBZV9uuNu1at26OvPfiqtja16azqcn3ymoW6dvF0mdG6AgCMTCa1qOZLapJ0u5m9aGY/MLOSEOrAOIpGTDfW1eiBT16hr76zTke7enTrz57Xjd/6ox5+eZ+yYS4YACB7hDGCs0zS05IudfdnzOzrkprd/R/7bXerpFslac6cOefv2LFjXOtEevX0xvXbF1/XNx7epJ0Hj6pu9mR96tozdPnCCkZ0AAApy5izqMxshqSn3X1u8PoySZ9z9/rBPkOLKnd198b16+d36ZsPb9brh4/q/NOm6FPXnqFLTp9G0AEADCtjWlTuvlfSTjNbFKxaLuml8a4DmSEvGtG7LpyjRz5zpb741iV6/dBRvfsHz+idtz2tp7ceCLs8AECWCuU6OGZ2jqQfSMqXtFXSe9390GDbM4IzcXR09+rfn9upbz+yWY0tnbrk9Gn61LVnaNncqWGXBgDIQBnTohoJAs7E09HdqzueeU3ffXSz9rd2qSQ/qtLCmMoK81RWGFNpQUzlScvH1hfGVB5sl1h//L2CWIS2FwDkmMECTiyMYoDhFOZF9b43ztNNF87Wr5/fpe0H2tXa0aOWzm61dPSouaNHuw8fVUtHj1o6enS0u3fYfeZFrV/wiam0IC8IRLHBA1Ty+vyYIlyRGQAyHgEHGa04P6ZbLp477HY9vXG1dvYcCzwtHYkglFjXreak5ZaOnkRY6ujRrkPtSZ/rVirXH+wLSMkjRIONHCWC0vFt+oJVQSw6+v84AIBBEXCQE2LRiCYX52tycf6I9+HuOtrde0JA6nu0Jo0ctfYLUIfbu7TzYLtaggDV0R0fvt6IKRoxRcxkphOeI8deH1+OWOLq0JFI3+sTtzclvY4M8Xkb5PMpbHPSPiMnbm/qe933ueOfOeH1ANsN9Dkp6diRYT4nHfu5j3+u72c6ebsTXgfbyU78XCRimlaSr6qyQhXlE0iBbEPAAQJmpuL8mIrzY5peXjji/XT1xNUWjAo1d3SfMELUF4paO3sUd5e7FI+74i65gtfuwSMRuuJxnfg6WD72+RO2H36b3nj82Hsn7DMuuYb5fLzv/RM/3xts50nbu07cxpM+k23KCxP/m6gqL9D0skJVlReqqqxA08sLNb088VxZVqDCPIIQkCkIOMAYy49FlB/L15SSkY8m5br+gSc53LkPHowG2m6gz0lJISw+zP41cMjs6XXtb+1UY0unGps7tK+5U40tHXpm20E1tnSou/fkpDapKE/TywtUVRaEofJCTS8rUFUQhPrW06IE0o+AA2DcHWtbKTsnbLu7DrV3q7ElEXz2NXeosblDjS2J5X3Nndq2tW3QIDS5OC8YCUqEnr5RoKqkMFRZRhACRoOAAwCnyMw0tSRfU0vydeaMwbeLx12H2ruOjf409oWhviDU0qnNjfvV1NKpngF6d1OK84LWWF9LrC8IHR8hqiwtUH4sjNsKApmNgAMAaRKJmKaVFmhaaYEWq3zQ7eJx18H2rmPhp68llvz61b0tamrtVO8AQWhqSf4Jc4L6RoWS5wpVlhUoL0oQwsRBwAGAkEUiporSAlWUFujsIbbrjbsOtvUFob4RoU7tazneInt5b7OaWjpPmsxtJk0uytOk4FEePCYN8ygvylNZAdd/QvYh4ABAlohGTJVlifk50qRBt+uNuw60dR5rifW1yPa3durI0R4dOdqtI0e7tevQUTUHywO1yPpETCor7B98YscC0FABqawwT1HCEUJAwAGAHBONWGKeTlmhlswcPAj1cXe1d/UeCz7Jj+YB1h052q3dR46q+WiPmo92q6t36Gs/lRXGTgxHfWGpOG/IkFReGFOMthpGiIADABOcmamkIKaSgphqJhed0mfdXR3d8QFD0GAhaXNT67F1nT1Dh6PSguMjReX9gtKkojwV5kUVi5pi0YjyIsFz1BSLRBSLWr/liGKR4Dl4nRe8F4vaseW+7aIR4/51WYyAAwAYMTNTUX5URflRzZh06hfI7OjuHXSUaKCQtP1Am5qDNlsq96AbraECUt/yscB0LCz1ha2hgldiX7FoRPnBdrGIqSAWORY2y4Ln0uDWMKUFMRXnRwldKSLgAABCU5gXVWFeVFUjuHp4V09cnT296ul1dcfj6un1E5a7e+Pqibt6euPqPvY6sdzT60nLcXUH2524r+Pru/u270l6P+nzPfHE/rt64mrr6h12X321DXRW3FDMpNL848HneBCKqrQgT6UF0X7rj4ej/utzPSwRcAAAWSlx1fDsnqPj7sfDU68fu9VL3y1dkpdbOxKvW05Y36vWjsRFJ9s6e9XS0a22rt6UglPEpJL848GntF8Y6ls+PoqUCFElBVGVBc992xXlZV5YIuAAABASM1N+zJSv40EtcZbcyPXNi0oOSS0d/cLSEOsbWzrUesJ984Y/ZsQ0aFvt/NOm6P2XzR/VzzQSBBwAAHJI8ryosQhLR7t7k0aQetXS2a22zl61dnYHI0gDjDR1JcLT3iMdmlYazn35CDgAAGBAZqbi/JiK82OqKgu7mlOT3c1LAACAARBwAABAziHgAACAnEPAAQAAOYeAAwAAcg4BBwAA5BwCDgAAyDkEHAAAkHPM/dRu9BUGM2uStCONh6iQtD+N+8fo8R1lPr6jzMd3lPn4jk7dae5e2X9lVgScdDOz1e6+LOw6MDi+o8zHd5T5+I4yH9/R2KFFBQAAcg4BBwAA5BwCTsJtYReAYfEdZT6+o8zHd5T5+I7GCHNwAABAzmEEBwAA5JwJHXDM7Doze8XMNpvZ58KuBycys9lm9oiZbTSzDWb28bBrwsDMLGpmL5rZyrBrwcDMbLKZ3WVmLwf/pi4OuyacyMw+GfyuW29md5pZYdg1ZbMJG3DMLCrp25Kul7RY0k1mtjjcqtBPj6RPu/tZki6S9GG+o4z1cUkbwy4CQ/q6pHvd/UxJdeL7yihmNlPSxyQtc/clkqKS3hVuVdltwgYcSRdK2uzuW929S9IvJb0l5JqQxN33uPsLwXKLEr+QZ4ZbFfozs1mS6iX9IOxaMDAzK5d0uaQfSpK7d7n74VCLwkBikorMLCapWNLukOvJahM54MyUtDPp9S7xf54Zy8zmSjpX0jMhl4KTfU3SZyXFQ64Dg5svqUnS7UEr8QdmVhJ2UTjO3V+X9GVJr0naI+mIu98fblXZbSIHHBtgHaeUZSAzK5X0a0mfcPfmsOvBcWa2QlKjuz8fdi0YUkzSeZK+6+7nSmqTxLzDDGJmU5ToIsyTVCOpxMxuDreq7DaRA84uSbOTXs8Sw4EZx8zylAg3d7j7b8KuBye5VNKNZrZdiTbv1Wb283BLwgB2Sdrl7n0joHcpEXiQOa6RtM3dm9y9W9JvJF0Sck1ZbSIHnOckLTSzeWaWr8Rkrt+HXBOSmJkpMWdgo7t/Jex6cDJ3/3t3n+Xuc5X4N/Swu/NXZ4Zx972SdprZomDVckkvhVgSTvaapIvMrDj43bdcTAQflVjYBYTF3XvM7COS7lNitvqP3H1DyGXhRJdKukXSOjP7c7DuH9z9nvBKArLWRyXdEfxBt1XSe0OuB0nc/Rkzu0vSC0qcQfqiuKrxqHAlYwAAkHMmcosKAADkKAIOAADIOQQcAACQcwg4AAAg5xBwAABAziHgAACAnEPAAQAAOYeAAwAAcg4BBwAA5BwCDgAAyDkEHAAAkHMIOAAAIOcQcACMmJm5mS0Ilr9nZv+YyrYjOM67zez+kdYJYOIh4AATmJndZ2b/PMD6t5jZXjOLpbovd/+Au/+vMahpbhCGjh3b3e9w9zeNdt8DHOtKM9s11vsFED4CDjCx/VjSLWZm/dbfIukOd+8Z/5IAYPQIOMDE9jtJUyVd1rfCzKZIWiHpp2Z2oZk9ZWaHzWyPmX3LzPIH2pGZ/djMvpj0+r8Hn9ltZn/Tb9t6M3vRzJrNbKeZfSHp7ceD58Nm1mpmF5vZX5vZk0mfv8TMnjOzI8HzJUnvPWpm/8vM/mhmLWZ2v5lVnOp/GDM7K9jXYTPbYGY3Jr13g5m9FOz/dTP7TLC+wsxWBp85aGZPmBm/Z4EQ8A8PmMDc/aik/5D0V0mr3yHpZXdfI6lX0iclVUi6WNJySR8abr9mdp2kz0i6VtJCSdf026QtOOZkSfWSPmhmbw3euzx4nuzupe7+VL99T5W0StI3JE2T9BVJq8xsWtJmfynpvZKqJOUHtaTMzPIk3S3p/mAfH5V0h5ktCjb5oaS/dfcySUskPRys/7SkXZIqJU2X9A+S/FSODWBsEHAA/ETSfzWzouD1XwXr5O7Pu/vT7t7j7tsl/ZukK1LY5zsk3e7u6929TdIXkt9090fdfZ27x919raQ7U9yvlAhEm9z9Z0Fdd0p6WVJD0ja3u/urSQHunBT33eciSaWS/sXdu9z9YUkrJd0UvN8tabGZlbv7IXd/IWl9taTT3L3b3Z9wdwIOEAICDjDBufuTkpokvcXM5ku6QNIvJMnMzghaLnvNrFnS/6vEaM5waiTtTHq9I/lNM3uDmT1iZk1mdkTSB1Lcb9++d/Rbt0PSzKTXe5OW25UIK6eiRtJOd48Pcoy3S7pB0g4ze8zMLg7W/6ukzZLuN7OtZva5UzwugDFCwAEgST9VYuTmFkn3u/u+YP13lRgdWeju5Uq0XPpPSB7IHkmzk17P6ff+LyT9XtJsd58k6XtJ+x1uxGO3pNP6rZsj6fUU6krVbkmz+82fOXYMd3/O3d+iRPvqd0qMEsndW9z90+4+X4kRpU+Z2fIxrAtAigg4AKREwLlG0n9T0J4KlElqltRqZmdK+mCK+/sPSX9tZovNrFjS5/u9XybpoLt3mNmFSsyZ6dMkKS5p/iD7vkfSGWb2l2YWM7N3SlqsRAtpRMysMPkh6Vkl5gl91szyzOxKJQLLL80sP7guzyR371biv09vsJ8VZrYgOCutb33vSOsCMHIEHAAK5tf8SVKJEiMrfT6jRPhokfR9Sf+e4v7+IOlrSky+3azjk3D7fEjSP5tZi6R/UjACEny2XdL/lvTH4Gyki/rt+4ASZ3l9WtIBSZ+VtMLd96dS2wBmSjra7zFb0o2Srpe0X9J3JP2Vu78cfOYWSduDtt0HJN0crF8o6UFJrZKekvQdd390hHUBGAVj/hsAAMg1jOAAAICcQ8ABAAA5h4ADAAByDgEHAADkHAIOAADIObGwC0hFRUWFz507N+wyAABAhnn++ef3u3tl//VZEXDmzp2r1atXh10GAADIMGbW/9YtkmhRAQCAHETAAQAAOYeAAwAAcg4BBwAA5BwCDgAAyDkEHAAAkHMmfMBxd8Xj3FEdAIBcMqEDzubGVl355Uf15Ob9YZcCAADG0IQOOLOmFOlga5dWrt0ddikAAGAMTeiAU5gX1bVnT9e96/eqs6c37HIAAMAYmdABR5Ia6mrU3NGjJ16lTQUAQK5IW8Axsx+ZWaOZrU9aN9XMHjCzTcHzlHQdP1VvXFChycV5ups2FQAAOSOdIzg/lnRdv3Wfk/SQuy+U9FDwOlR50YiuX1KtB17ap6NdtKkAAMgFaQs47v64pIP9Vr9F0k+C5Z9Iemu6jn8qGuqq1d7Vq4dfbgy7FAAAMAbGew7OdHffI0nBc9U4H39Ab5g3TZVlBZxNBQBAjsjYScZmdquZrTaz1U1NTWk9VjRiql9arYdfblRLR3dajwUAANJvvAPOPjOrlqTgedCekLvf5u7L3H1ZZWVl2gtrqKtWZ09cD27cl/ZjAQCA9BrvgPN7Se8Jlt8j6T/H+fiDOnf2FM2cXKS71+wJuxQAADBK6TxN/E5JT0laZGa7zOx9kv5F0rVmtknStcHrjBCJmFbUVuvxV5t0uL0r7HIAAMAopPMsqpvcvdrd89x9lrv/0N0PuPtyd18YPPc/yypUDXU16om77l2/N+xSAADAKGTsJOMwnF1TrrnTirnoHwAAWY6Ak8TM1FBXo6e2HFBTS2fY5QAAgBEi4PTTUFejuEt/WM9kYwAAshUBp58zppdp0fQy3b2GNhUAANmKgDOAhrpqPbf9kHYfPhp2KQAAYAQIOANYUVsjSVq1ljYVAADZiIAzgLkVJVo6cxJnUwEAkKUIOINoqKvW2l1HtONAW9ilAACAU0TAGUR90KZaSZsKAICsQ8AZxMzJRVp22hTOpgIAIAsRcIbQUFejl/e26NV9LWGXAgAATgEBZwjXL52hiEkrGcUBACCrEHCGUFVWqIvmT9Pda/fI3cMuBwAApIiAM4yGuhpt29+mDbubwy4FAACkiIAzjOvOnqFYxLgmDgAAWYSAM4wpJfm6bGGFVq6hTQUAQLYg4KSgoa5Grx8+qhdeOxx2KQAAIAUEnBRcu3i68mMRrokDAECWIOCkoKwwT1ctqtSqdXvUG6dNBQBApiPgpKihrkZNLZ16dtvBsEsBAADDIOCk6Oozq1ScH+VsKgAAsgABJ0XF+TFdc9Z0/WHdHnX3xsMuBwAADIGAcwoa6mp0qL1bf9y8P+xSAADAEAg4p+DyMypUVhjT3Wv2hF0KAAAYAgHnFBTEonrz2TN0/4a96ujuDbscAAAwCALOKWqoq1FLZ48ef7Up7FIAAMAgCDin6JLTp2lqSb7uXkubCgCATEXAOUV50YiuXzJDD760T+1dPWGXAwAABkDAGYGGuhod7e7VQxsbwy4FAAAMgIAzAhfMnaqqsgLuTQUAQIYi4IxANGKqr63Wo680qbmjO+xyAABAPwScEWqoq1FXb1wPbNgXdikAAKAfAs4InTt7smZOLuLeVAAAZCACzgiZmRrqavTkpv062NYVdjkAACBJKAHHzD5uZuvNbIOZfSKMGsZCQ121euKue9fvDbsUAACQZNwDjpktkfTfJF0oqU7SCjNbON51jIXF1eWaX1HC2VQAAGSYMEZwzpL0tLu3u3uPpMckvS2EOkbNzLSirkZPbzugxuaOsMsBAACBMALOekmXm9k0MyuWdIOk2SHUMSYaaqvlLt2zjls3AACQKcY94Lj7RklfkvSApHslrZF00j0PzOxWM1ttZqubmjL3xpYLp5fpzBll3JsKAIAMEsokY3f/obuf5+6XSzooadMA29zm7svcfVllZeX4F3kKGupq9PyOQ9p1qD3sUgAAgMI7i6oqeJ4j6S8k3RlGHWOlobZGkrSKURwAADJCWNfB+bWZvSTpbkkfdvdDIdUxJuZMK1bdrElc9A8AgAwRVovqMndf7O517v5QGDWMtYa6Gq1/vVnb9reFXQoAABMeVzIeI/W11ZKklVwTBwCA0BFwxkj1pCJdOHcqbSoAADIAAWcMNdRV69V9rXplb0vYpQAAMKERcMbQ9UurFTFx6wYAAEJGwBlDFaUFuuT0Ct29drfcPexyAACYsAg4Y6yhrlo7DrRr3etHwi4FAIAJi4Azxt589gzlRU0ruegfAAChIeCMscnF+bp8YaVWrtmteJw2FQAAYSDgpEFDXY12H+nQC69l9QWaAQDIWgScNLhm8XQVxCKcTQUAQEgIOGlQWhDT1WdWadW6PerpjYddDgAAEw4BJ00a6mq0v7VLz2w7GHYpAABMOAScNLlqUZVK8qO0qQAACAEBJ02K8qO6dvF03bthr7p6aFMBADCeCDhp1FBXo8Pt3frj5v1hlwIAwIRCwEmjyxZWqrwwRpsKAIBxRsBJo/xYRNctmaH7X9qnju7esMsBAGDCIOCkWUNdjVo7e/ToK41hlwIAwIRBwEmzi+dP07SSfN29hntTAQAwXgg4aRaLRnTD0mo99PI+tXX2hF0OAAATAgFnHDTU1aijO64HN+4LuxQAACYEAs44WHbaFM0oL6RNBQDAOCHgjINIxFRfW63HXm3UkfbusMsBACDnEXDGSUNdjbp7Xfe9tDfsUgAAyHkEnHFSN2uSZk8t4qJ/AACMAwLOODEzNdTW6E9bDuhAa2fY5QAAkNOGDThmdqmZlQTLN5vZV8zstPSXlnsa6mrUG3f9YT1tKgAA0imVEZzvSmo3szpJn5W0Q9JP01pVjjpzRplOryyhTQUAQJqlEnB63N0lvUXS193965LK0ltWbjIzNdTV6NntB7X3SEfY5QAAkLNSCTgtZvb3km6WtMrMopLy0ltW7lpRWyN3adU6rokDAEC6pBJw3impU9L73H2vpJmS/jWtVeWwBVWlWlxdTpsKAIA0SmkER4nW1BNmdoakcyTdmdaqclxDXY3+vPOwdh5sD7sUAAByUioB53FJBWY2U9JDkt4r6cfpLCrXraitliStXEubCgCAdEgl4Ji7t0v6C0nfdPe3STo7vWXlttlTi3XO7Mm0qQAASJOUAo6ZXSzp3ZJWBeui6StpYmioq9FLe5q1ubE17FIAAMg5qQScT0j6e0m/dfcNZjZf0iOjOaiZfdLMNpjZejO708wKR7O/bFS/tFpm0sq1jOIAADDWhg047v6Yu98o6TtmVuruW939YyM9YDCX52OSlrn7EiVGg9410v1lqxmTCnXh3Km6e81uJS4zBAAAxkoqt2pYamYvSlov6SUze97MRjsHJyapyMxikoolTchhjIa6Gm1patPLe1vCLgUAgJySSovq3yR9yt1Pc/c5kj4t6fsjPaC7vy7py5Jek7RH0hF3v7//dmZ2q5mtNrPVTU1NIz1cRrt+yQxFI8ZkYwAAxlgqAafE3Y/NuXH3RyWVjPSAZjZFids+zJNUI6nEzG7uv5273+buy9x9WWVl5UgPl9GmlRboktOn6e61tKkAABhLqQScrWb2j2Y2N3j8D0nbRnHMayRtc/cmd++W9BtJl4xif1mtoa5GOw8e1ZpdR8IuBQCAnJFKwPkbSZVKBJHfSKqQ9NejOOZrki4ys2IzM0nLJW0cxf6y2pvPnqG8KG0qAADGUipnUR1y94+5+3nB4xNKzMsZEXd/RtJdkl6QtC6o4baR7i/bTSrK0xVnVGnV2j2Kx2lTAQAwFlIZwRnIxaM5qLt/3t3PdPcl7n6Lu3eOZn/ZrqGuWnubO7R6x6GwSwEAICeMNOBgDF1z1nQV5kVoUwEAMEZig71hZucN9pakvPSUMzGVFMS0/MzpumfdHn2+YbFiUXInAACjMWjAkfR/h3jv5bEuZKJrqKvWqnV79NTWA7psYW6eFg8AwHgZNOC4+1XjWchEd+WiKpUWxHT3mt0EHAAARoleSIYozIvqTYun6971e9XVEw+7HAAAshoBJ4M01NWouaNHT2zKzVtTAAAwXgg4GeTSBRWaVJTH2VQAAIzSSM6ikiS5+wtjX87Elh+L6PolM3T3mt062tWrovxo2CUBAJCVRnoWlUu6eoxrgRJtql8+t1OPvNKoG5ZWh10OAABZibOoMsxF86eporRAd6/ZTcABAGCEhhrBOcbMlkhaLKmwb527/zRdRU1k0YipfukM/fK5nWrt7FFpQUpfEQAASDLsJGMz+7ykbwaPqyT9H0k3prmuCa2hrkadPXE9+NK+sEsBACArpXIW1X+RtFzSXnd/r6Q6SQVprWqCO2/OFFVPKuRsKgAARiiVgHPU3eOSesysXFKjpPnpLWtii0RMK2qr9fimJh1u7wq7HAAAsk4qAWe1mU2W9H1Jz0t6QdKz6SwKiTZVd6/rvg17wy4FAICsM2jAMbNvmdkl7v4hdz/s7t+TdK2k9wStKqTR0pmTdNq0Yt29Zk/YpQAAkHWGGsHZJOn/mtl2M/uSmZ3j7tvdfe14FTeRmZkaamv0py371dTSGXY5AABklUEDjrt/3d0vlnSFpIOSbjezjWb2T2Z2xrhVOIE11NUo7tK96xnFAQDgVAw7B8fdd7j7l9z9XEl/KeltkjamvTJo0YwyLawqpU0FAMApSuU6OHlm1mBmd0j6g6RXJb097ZVBUmIU59ntB7XnyNGwSwEAIGsMNcn4WjP7kaRdkm6VdI+k0939ne7+u3Gqb8JbUZu4XcOqtYziAACQqqFGcP5B0lOSznL3Bne/w93bxqkuBOZXlmrJzHIu+gcAwCkYapLxVe7+fXc/OJ4F4WQNtTVas+uIdhwgXwIAkIpULvSHkNUHbaqVtKkAAEgJAScLzJpSrPPmTKZNBQBAigg4WaKhrkYv723Rpn0tYZcCAEDGI+Bkifql1TKT7qZNBQDAsAg4WaKqvFAXzZumlWt2y93DLgcAgIxGwMkiDXU12rq/TRt2N4ddCgAAGY2Ak0WuWzJDsYjp7rVMNgYAYCgEnCwytSRfly6o0Mo1e2hTAQAwBAJOlmmoq9Hrh4/qxZ2Hwy4FAICMRcDJMm86e7ryoxGuiQMAwBAIOFmmvDBPVy6q1Kq1e9Qbp00FAMBAxj3gmNkiM/tz0qPZzD4x3nVks4a6GjW2dOrZbdwmDACAgYx7wHH3V9z9HHc/R9L5ktol/Xa868hmy8+qUlFelLOpAAAYRNgtquWStrj7jpDryCrF+TEtP6tK967fq+7eeNjlAACQccIOOO+SdGfINWSlhroaHWzr0p+2HAi7FAAAMk5oAcfM8iXdKOlXg7x/q5mtNrPVTU1N41tcFrjijEqVFcQ4mwoAgAGEOYJzvaQX3H3fQG+6+23uvszdl1VWVo5zaZmvMC+qN509Q/et36vOnt6wywEAIKOEGXBuEu2pUWmoq1ZLZ48ee4URLgAAkoUScMysWNK1kn4TxvFzxaULKjSlOE93r90TdikAAGSUUAKOu7e7+zR3PxLG8XNFXjSi65ZU68GX9qm9qyfscgAAyBhhn0WFUWqoq9bR7l49/HJj2KUAAJAxCDhZ7g3zpqmyrICzqQAASELAyXLRiKl+abUeeaVJzR3dYZcDAEBGIODkgIa6GnX1xPXAhgHPuAcAYMIh4OSA8+ZM1szJRdybCgCAAAEnB5iZVtRW68lN+3WorSvscgAACB0BJ0c01NWoJ+66d8PesEsBACB0BJwccXZNueZVlHA2FQAAIuDkDDNTQ221ntp6QI3NHWGXAwBAqAg4OaShrkbu0j3ruHUDAGBiI+DkkIXTy7Roepn+Y/UuHWjtDLscAABCQ8DJMe974zxt3NusN37pEX1x5Uu0qwAAE1Is7AIwtt5xwWydd9pkfeeRLbr9T9v106d36J3LZutvr5ivWVOKwy4PAIBxYe4edg3DWrZsma9evTrsMrLOjgNt+t5jW3TX87vkLr3t3Jn60FULNK+iJOzSAAAYE2b2vLsvO2k9ASf37T58VLc9vlV3PvuaunvjWlFbow9ftUCLZpSFXRoAAKNCwIGaWjr1gye36udP7VBbV6/etHi6PnL1AtXOmhx2aQAAjAgBB8ccauvS7X/arh//cZuaO3p0xRmV+sjVC3TB3KlhlwYAwCkh4OAkLR3d+tnTO/SDJ7bpYFuX3jBvqj569UJdumCazCzs8gAAGBYBB4Nq7+rRnc/u1G2Pb9G+5k6dM3uyPnLVAi0/q4qgAwDIaAQcDKuzp1d3Pb9L3310i3YdOqqzqsv1kasW6LolMxSNEHQAAJmHgIOUdffG9Z9/3q3vPLpZW5vadHpliT581QLdWFejWJRrQwIAMgcBB6esN+76w/o9+tbDm/Xy3hbNnlqkD16xQG8/f6YKYtGwywMAgICDkXN3PbSxUd98eJPW7DqiGeWF+tsr5utdF8xRUT5BBwAQHgIORs3d9eTm/frmw5v17LaDmlaSr/dfNl83XzRHZYV5YZcHAJiACDgYU89uO6hvPbJZj7/apElFeXrvpXP115fM1eTi/LBLAwBMIAQcpMWanYf1rUc264GX9qkkP6pbLp6r9182TxWlBWGXBgCYAAg4SKuX9zbr249s0cq1u1UQi+imC+fo1svnq3pSUdilAQByGAEH42JLU6u+++gW/fbF1xU109vPn6UPXnG65kwrDrs0AEAOIuBgXO082K7vPbZFv1q9S73uess5NfrQlQu0oKo07NIAADmEgINQ7D3Soe8/sVV3PLNDnT1x3bCkWh++aoEW15SHXRoAIAcQcBCqA62d+uGT2/TTp3aotbNH15xVpQ9ftUDnzpkSdmkAgCxGwEFGONLerZ88tV0/+uM2HW7v1hsXVOgjVy/QG+ZN5caeAIBTRsBBRmnt7NEdT+/Q95/Yqv2tXbpg7hR95OqFunxhBUEHAJAyAg4yUkd3r/79uZ363mNbtOdIh5bOnKSPXL1A1541XRHuYA4AGEZGBRwzmyzpB5KWSHJJf+PuTw22PQEn93X1xPWbF3bpu49t0Y4D7Vo0vUwfvnqB6pdWK0rQAQAMItMCzk8kPeHuPzCzfEnF7n54sO0JOBNHT29cK9fu0bce2azNja2aV1GiD155uq5aVKWpJfmEHQDACTIm4JhZuaQ1kuZ7igcn4Ew88bjrvg179a1HNmvD7mZJUjRimlaSr8qygsSjtOD4cr/XpQUx5vIAwAQwWMCJhVDLfElNkm43szpJz0v6uLu3hVALMlQkYrp+abWuWzJDT205oM1NrWpq6Tz+aO3Uy3tatL+1Uz3xk3NyYV5ElWUFqiorHDIIVZQWKD8WCeEnBACkUxgjOMskPS3pUnd/xsy+LqnZ3f+x33a3SrpVkubMmXP+jh07xrVOZId43HX4aHdS8Ok4KQj1LR9q7x5wH5OL804MQaUFqirvWy48tn5yUR4TnwEgw2RSi2qGpKfdfW7w+jJJn3P3+sE+Q4sKY6GrJ64DbZ1qbD45/CS/bmzpUEd3/KTPxyKmitKBR4L6HlXBc3F+GIOjADDxZEyLyt33mtlOM1vk7q9IWi7ppfGuAxNPfiyi6klFw97h3N3V1tV7Yvhp6VBjUhDa19yh9a8f0f7WTg3QIVNJfnTQtlhlWYGmFB+fMG0KnvsNDvW97v9+8vrjyye+p/6fOfa+Dbj9sDWk8LlYxFSUH1VhLMpIF4DQhfVn5kcl3RGcQbVV0ntDqgM4iZmptCCm0oKY5lWUDLltb9x1qL1r0LZYU0unXtnboidb9qu5o2ecfoLw5cciKsqLqjCv7znxKMqLJkJQXuTEdXnH1/WFpKL8xPqCpH0UJb1fmB9RfjTCZHIAAwol4Lj7nyWdNJwEZJto0LaqKC3QWdVDb9vR3av9rX3zgbrkLvV1iPsGgfpaxsdf933aj73u/54nvTfQvjTc9sPUoGGPk3ivp9fV0d2ro8Gjszuuo12J5b71Hd29amrpSWzT1avOnt5j2ww0EjaciOlY8CnsC1RJAel4iDoxaB1bl39i+DoeohJhq6K0QIV50VMvDEDomCgAjJPCvKhmTSnWrCnFYZeScdxd3b0eBKPjIakjCEkdSSGpb31HEJJOClXBtq2dPWpq6VRnz4lBq7Pn5PlVQykvjKmqvFDTyxNn5VUFz8delyUmpTPvCsgs/IsEEDozU37MEqfsF+Wl9VjxuKujJwhPSSGpIzlUdfeqvbNH+1s71diSmHPV2NKpZ7cdVGNLh7p7Tx5uKiuIHQs/VeUFml7eF36C57LEupICfu0C44F/aQAmlEjEVJwfU3H+yD7v7jrc3q19LR1qbD4egJqSgtDzOw6psaVTXQOMFpXkRzW9PHH5geMhqOCkdVysEhgdAg4AnAIz05SSfE0pydeZMwbfzt3VfLTnWBDqCz+Nx4JRh/688/CglyUoyoue1BZLBKHjLbLKskKVFxKEgIEQcAAgDcxMk4rzNKk4T2dMLxt0O3dXS2ePGpuDIHQsEAVhqKVT618/on3NjTra3XvS5wvzIsfmAg02MlRVVqBJRXkEIUwoBBwACJGZqbwwT+WFeVpQNXQQau3sSYwCNR8fCUoeGdq4p1mPvdqp1s6TL0mQH4uosrRA00rzNbUk8ZhWkq+pJQWaFoxIHVtXmq8yWmTIcgQcAMgCZqaywjyVFebp9MrSIbdtC4LQsfDTfPxClQfbunSgtUub9rXqQFvngO0xScqPRjSlJO9YAJraLwD1haO+dZO4lQkyDAEHAHJMSUFM81K4UKUktXf16EBrlw62JR4H2rp0sK0z8dx6fN1rB9t1sK1rwNEhKXFNqCnFeUlBqOD48gmjRon1U4rzFItyo1ukDwEHACaw4vyYiqfGNHtqatdn6uju1aH2rgFDUd/o0KH2Lm3c26yDbV06PMhNbqXEjW77RoCmFCcHoX6jRsH6ghgXXUTqCDgAgJQV5kVTuqdbn57euA61dwdBqPN4KDohIHVq+4E2vfDaIR1s6xr0qtalBbF+84fyVZAXUcRMEUvcmy2xrOD18eWIKXgdrIuc4vbJ+4+c4vYnvJ849mDb50UjieBXnM8I1ygRcAAAaROLRo7dZFYafBJ1n3jcdeRodzAqdGK7rG/dofYu7TnSoQ27m9XdG1fcXXGX4u7y4Llvnfd7L5tMKjre8ptSfHz+09TiYHQrebkkX8X5USaGJyHgAAAyRiRy/DpDY81PCEDDB6J4/+3jp7i9+/H346lt39UT1+H2rqSAl3jsOtSutbsO62Bbl3oGGeIqiEVOOCMuebRrykmtwMSlA6I5PDGcgAMAmBCsr22k7P0/9b7rJvWNaB3qC0HtXSfMgTrQ1qXtB9p0qK170InhEZMm940ABc9Tktp/Az2y6eazBBwAALJE8nWT5qZwlpyUmBh+uL37hDlQB4NwlDxStKWpVYd2dA05D6o4P3rCqNCxcFR64ghRoqVWoPKi8K6nRMABACCHFeZFNWNSVDMmFaa0fd88qL5RoYEeB5Kup3SwrWvAq2xLUixiumFptb5x07lj+SOlhIADAACOSZ4HdXplap852tWrA22dOtSWGClKvpTA3GmpjTSNNQIOAAAYlaL8qGblF2vWlLArOY6T7AEAQM4h4AAAgJxDwAEAADmHgAMAAHIOAQcAAOQcAg4AAMg5BBwAAJBzCDgAACDnmGfB/ePNrEnSjjQeokLS/jTuH6PHd5T5+I4yH99R5uM7OnWnuftJ11zOioCTbma22t2XhV0HBsd3lPn4jjIf31Hm4zsaO7SoAABAziHgAACAnEPASbgt7AIwLL6jzMd3lPn4jjIf39EYYQ4OAADIOYzgAACAnDOhA46ZXWdmr5jZZjP7XNj14ERmNtvMHjGzjWa2wcw+HnZNGJiZRc3sRTNbGXYtGJiZTTazu8zs5eDf1MVh14QTmdkng991683sTjMrDLumbDZhA46ZRSV9W9L1khZLusnMFodbFfrpkfRpdz9L0kWSPsx3lLE+Lmlj2EVgSF+XdK+7nympTnxfGcXMZkr6mKRl7r5EUlTSu8KtKrtN2IAj6UJJm919q7t3SfqlpLeEXBOSuPsed38hWG5R4hfyzHCrQn9mNktSvaQfhF0LBmZm5ZIul/RDSXL3Lnc/HGpRGEhMUpGZxSQVS9odcj1ZbSIHnJmSdia93iX+zzNjmdlcSedKeibkUnCyr0n6rKR4yHVgcPMlNUm6PWgl/sDMSsIuCse5++uSvizpNUl7JB1x9/vDrSq7TeSAYwOs45SyDGRmpZJ+LekT7t4cdj04zsxWSGp09+fDrgVDikk6T9J33f1cSW2SmHeYQcxsihJdhHmSaiSVmNnN4VaV3SZywNklaXbS61liODDjmFmeEuHmDnf/Tdj14CSXSrrRzLYr0ea92sx+Hm5JGMAuSbvcvW8E9C4lAg8yxzWStrl7k7t3S/qNpEtCrimrTeSA85ykhWY2z8zylZjM9fuQa0ISMzMl5gxsdPevhF0PTubuf+/us9x9rhL/hh52d/7qzDDuvlfSTjNbFKxaLumlEEvCyV6TdJGZFQe/+5aLieCjEgu7gLC4e4+ZfUTSfUrMVv+Ru28IuSyc6FJJt0haZ2Z/Dtb9g7vfE15JQNb6qKQ7gj/otkp6b8j1IIm7P2Nmd0l6QYkzSF8UVzUeFa5kDAAAcs5EblEBAIAcRcABAAA5h4ADAAByDgEHAADkHAIOAADIOQQcAOPGzHrN7M9JjzG7mq6ZzTWz9WO1PwDZbcJeBwdAKI66+zlhFwEg9zGCAyB0ZrbdzL5kZs8GjwXB+tPM7CEzWxs8zwnWTzez35rZmuDRd0n7qJl938w2mNn9ZlYUbP8xM3sp2M8vQ/oxAYwjAg6A8VTUr0X1zqT3mt39QknfUuIO5QqWf+rutZLukPSNYP03JD3m7nVK3FOp7yrkCyV9293PlnRY0tuD9Z+TdG6wnw+k50cDkEm4kjGAcWNmre5eOsD67ZKudvetwQ1W97r7NDPbL6na3buD9XvcvcLMmiTNcvfOpH3MlfSAuy8MXv+dpDx3/6KZ3SupVdLvJP3O3VvT/KMCCBkjOAAyhQ+yPNg2A+lMWu7V8XmG9ZK+Lel8Sc+bGfMPgRxHwAGQKd6Z9PxUsPwnJe5SLknvlvRksPyQpA9KkplFzax8sJ2aWUTSbHd/RNJnJU2WdNIoEoDcwl8xAMZTUdKd4SXpXnfvO1W8wMyeUeIPr5uCdR+T9CMz+++SmnT8Dtgfl3Sbmb1PiZGaD0raM8gxo5J+bmaTJJmkr7r74TH6eQBkKObgAAhdMAdnmbvvD7sWALmBFhUAAMg5jOAAAICcwwgOAADIOQQcAACQcwg4AAAg5xBwAABAziHgAACAnEPAAQAAOef/B1UXWu3SBqgjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn = NeuralNetwork(nn_arch=[{'input_dim': 64, 'output_dim': 16, 'activation': best_activation_layer1},\n",
    "                               {'input_dim': 16, 'output_dim': 64, 'activation': best_activation_layer2}],\n",
    "                               lr=best_lr, batch_size=200, seed=42, epochs=10, loss_function=\n",
    "                               'mean_squared_error') \n",
    "\n",
    "#X_train and y_train are the same observations that were used for cross validation grid search\n",
    "#X_test and y_test were completely held out of the grid search procedure\n",
    "per_epoch_train_loss, per_epoch_val_loss = nn.fit(X_train,y_train,\n",
    "                                               X_test,y_test)\n",
    "\n",
    "\n",
    "\n",
    "loss_hist = per_epoch_train_loss\n",
    "loss_hist_val = per_epoch_val_loss\n",
    "assert len(loss_hist) > 0, \"Need to run training before plotting loss history\"\n",
    "fig, axs = plt.subplots(2, figsize=(8,8))\n",
    "fig.suptitle('Loss History')\n",
    "axs[0].plot(np.arange(len(loss_hist)), loss_hist)\n",
    "axs[0].set_title('Training Loss')\n",
    "axs[1].plot(np.arange(len(loss_hist_val)), loss_hist_val)\n",
    "axs[1].set_title('Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "axs[0].set_ylabel('Train Loss')\n",
    "axs[1].set_ylabel('Val Loss')\n",
    "fig.tight_layout()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0e1ef6",
   "metadata": {},
   "source": [
    "### Average reconstruction error over entire dataset\n",
    "* Take trained model and form predictions on entire datase then calculate MSE across entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62330b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reconstruction error over entire dataset 19.38374331006017\n",
      "Average reconstruction error over unseen test data 19.28104426739745\n"
     ]
    }
   ],
   "source": [
    "#average MSE across entire dataset\n",
    "predictions = nn.predict(X)\n",
    "total_reconstruction_error = nn._mean_squared_error(X,predictions)\n",
    "print(f\"Average reconstruction error over entire dataset {total_reconstruction_error}\")\n",
    "\n",
    "#average MSE from unseen test data\n",
    "test_predictions = nn.predict(X_test)\n",
    "test_reconstruction_error = nn._mean_squared_error(X_test,test_predictions)\n",
    "print(f\"Average reconstruction error over unseen test data {test_reconstruction_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e72c38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
