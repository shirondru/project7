{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d20a027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "from numpy.typing import ArrayLike\n",
    "from nn import NeuralNetwork, one_hot_encode_seqs, sample_seqs,read_text_file,read_fasta_file, clip_sample_seqs\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89b20e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "rap1 = read_text_file(\"./data/rap1-lieb-positives.txt\")\n",
    "yeast_neg = read_fasta_file(\"./data/yeast-upstream-1k-negative.fa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c560d756",
   "metadata": {},
   "source": [
    "# Sampling Scheme: Upsampling\n",
    "* I chose to upsample the minority class to keep the dataset large enough to successfuly train a neural network, which needs a lot of data, while keeping the classes balanced. An alternative approach, like downsampling, would have kept 137 positive and 137 negative data points, which would have been a significant reduction in the sample size, possibly leading to a poorly trained model.\n",
    "* The upsampling procedure is implemented via sampling with replacement of the minority class, while keeping all members of the majority class. In this case, the positive positive Rap1 motifs will be resampled with replacement until there are an equal number of positive and negative motifs (3163 of each)\n",
    "* However, because the yeast negative sequences are much longer than the positive rap1 motifs, the dimensions of the two datasets are different. Therefore, I implemented clip_sample_seqs() to take the longer yeast negative sequences and clip/chunk each of them to produce multiple sequences of the same length as the rap1 motifs. Therefore, the 3163 yeast negative motifs ended up turning into far more smaller sequences that are the same length as the rap1 positive motifs. Upsampling therefore led to 366594 total sequences, with an equal 183297 in each class.\n",
    "* The resulting clipped yeast negative sequences and upsamples rap1 positive sequences were one hot encoded and used to train the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4f557c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "pos,neg = clip_sample_seqs(rap1,yeast_neg)\n",
    "#concatenate positive and negative and create a list of labels\n",
    "seqs = pos + neg\n",
    "labels = [True] * len(pos) + [False]*len(neg)\n",
    "\n",
    "X,y = sample_seqs(seqs,labels,random_state = 42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "X_train = one_hot_encode_seqs(X_train)\n",
    "X_train = np.stack(X_train,axis=0) #convert list of np arrays back into a 2D array\n",
    "\n",
    "X_test = one_hot_encode_seqs(X_test)\n",
    "X_test = np.stack(X_test,axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ffd963",
   "metadata": {},
   "source": [
    "### 5-fold CV Grid Search to find optimal learning rate and activation function hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870cd387",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shirondrusinsky/Documents/GitHub/project7/nn/nn.py:374: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-Z))\n"
     ]
    }
   ],
   "source": [
    "columns = [\"lr\",\"activation_layer1\",\"avg_train_error\",\"avg_val_error\"] + [f\"train_error_fold_{x}\" for x in range(1,6)] \\\n",
    "         + [f\"val_error_fold_{x}\" for x in range(1,6)]            \n",
    "tuning_results_df = pd.DataFrame(columns = columns)\n",
    "lrs = [0.01,0.001,0.0001]\n",
    "activations = ['relu','sigmoid']                                              \n",
    "kf = KFold(n_splits=5)\n",
    "df_idx = 0\n",
    "for lr in lrs:\n",
    "    for activation_layer1 in activations:\n",
    "        fold_avg_train_losses = []\n",
    "        fold_avg_val_losses = []\n",
    "        for fold_idx, (train,val) in enumerate(kf.split(X_train,y_train)):\n",
    "            fold_idx = fold_idx + 1\n",
    "            nn = NeuralNetwork(nn_arch=[{'input_dim': 68, 'output_dim': 16, 'activation': activation_layer1},\n",
    "                           {'input_dim': 16, 'output_dim': 1, 'activation': 'sigmoid'}],\n",
    "                           lr=lr, batch_size=10000, seed=42, epochs=100, loss_function=\n",
    "                           'cross_entropy') \n",
    "            #fit this fold. test data is still held out\n",
    "            train_loss, val_loss = nn.fit(X_train[train],y_train[train],\n",
    "                                           X_train[val],y_train[val])\n",
    "            fold_avg_train_loss = np.mean(train_loss) #avg (across epochs) training loss for this fold\n",
    "            fold_avg_train_losses.append(fold_avg_train_loss)\n",
    "\n",
    "            fold_avg_val_loss = np.mean(val_loss) #avg (across epochs) validation loss for this fold\n",
    "            fold_avg_val_losses.append(fold_avg_val_loss)\n",
    "\n",
    "\n",
    "            #store hyperparameters and per-fold results\n",
    "            tuning_results_df.loc[df_idx,\"lr\"] = lr\n",
    "            tuning_results_df.loc[df_idx,\"activation_layer1\"] = activation_layer1\n",
    "            tuning_results_df.loc[df_idx,f\"train_error_fold_{fold_idx}\"] = fold_avg_train_loss\n",
    "            tuning_results_df.loc[df_idx,f\"val_error_fold_{fold_idx}\"] = fold_avg_val_loss\n",
    "\n",
    "        #store average train and val loss across all folds for this combination of hyperparameters\n",
    "        tuning_results_df.loc[df_idx,\"avg_train_error\"] = np.mean(fold_avg_train_losses)\n",
    "        tuning_results_df.loc[df_idx,\"avg_val_error\"] = np.mean(fold_avg_val_losses)\n",
    "\n",
    "        df_idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1d1879",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resulting dataframe stores error from each fold with each combination of hyperparameters\n",
    "#as well as the average error across all 5 folds with each combnation of hyperparameters\n",
    "display(tuning_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e098c2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data for combination of hyperparameters that gave the lowest average binary cross entropy\n",
    "# across epochs and folds in the validation set\n",
    "display(tuning_results_df.loc[tuning_results_df['avg_val_error'].astype(float).idxmin()])\n",
    "best_lr = tuning_results_df.loc[tuning_results_df['avg_val_error'].astype(float).idxmin(),'lr']\n",
    "best_activation_layer1 = tuning_results_df.loc[tuning_results_df['avg_val_error'].astype(float).idxmin(),'activation_layer1']\n",
    "\n",
    "print(f\"The optimal learning rate was {best_lr}\")\n",
    "print(f\"The optimal activation function to use in layer 1 was {best_activation_layer1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518e80d6",
   "metadata": {},
   "source": [
    "### Re-training model with optimal set of hyperparameters and plotting per-epoch train and test binary cross entropy\n",
    "\n",
    "* I chose learning rate and activation function hyperparameters by implementing a cross-validated grid search; the hyperparameters that minimized the average across-fold binary cross entropy were used moving forward. A subset of samples were completely held out from this procedure to be used for validation/testing later in this notebook. \n",
    "* These results suggest the model was able to learn from the training data and properly generalize to the unseen  data, as the unseen validation loss decreased over the epochs\n",
    "\n",
    "\n",
    "### Why I chose Binary Cross Entropy as my loss function\n",
    "* Binary cross entropy was chosen as the loss function because this loss is minimized with correct binary classifications -- when a member of the 1 class is properly classified as a 1 or when a member of the 0 class is properly classified as a 0. Therefore, the goal of backpropagation is to minimize this loss. Using a different loss function, like mean squared error would be inappropriate because this loss is more appropriate for regression-like tasks rather than classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d5fe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate NN with best learning rate and layer 1 activation function\n",
    "#determined via grid search\n",
    "nn = NeuralNetwork(nn_arch=[{'input_dim': 68, 'output_dim': 16, 'activation': best_activation_layer1},\n",
    "                           {'input_dim': 16, 'output_dim': 1, 'activation': 'sigmoid'}],\n",
    "                           lr=best_lr, batch_size=10000, seed=42, epochs=100, loss_function=\n",
    "                           'cross_entropy') \n",
    "#X_train and y_train are the same observations that were used for cross validation grid search\n",
    "#X_test and y_test were completely held out of the grid search procedure\n",
    "per_epoch_train_loss, per_epoch_val_loss = nn.fit(X_train,y_train,\n",
    "                                               X_test,y_test)\n",
    "\n",
    "\n",
    "\n",
    "loss_hist = per_epoch_train_loss\n",
    "loss_hist_val = per_epoch_val_loss\n",
    "assert len(loss_hist) > 0, \"Need to run training before plotting loss history\"\n",
    "fig, axs = plt.subplots(2, figsize=(8,8))\n",
    "fig.suptitle('Loss History')\n",
    "axs[0].plot(np.arange(len(loss_hist)), loss_hist)\n",
    "axs[0].set_title('Training Loss')\n",
    "axs[1].plot(np.arange(len(loss_hist_val)), loss_hist_val)\n",
    "axs[1].set_title('Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "axs[0].set_ylabel('Train Loss')\n",
    "axs[1].set_ylabel('Val Loss')\n",
    "fig.tight_layout()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fef9420",
   "metadata": {},
   "source": [
    "### Performance of the Classifier on the test dataset\n",
    "* Take the trained model and quantify binary cross entropy error and accuracy on the held out test dataset\n",
    "* Also plot an ROC-AUC curve from the held out test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418ebe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nn.predict(X_test)\n",
    "test_bce = nn._binary_cross_entropy(y_test,predictions)\n",
    "print(f\"Average binary cross entropy error across held out test data {test_bce}\")\n",
    "\n",
    "#ROC curve\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr,tpr,_ = roc_curve(y_test.reshape(y_test.shape[0],1).astype(int),\n",
    "         predictions)\n",
    "\n",
    "#to get accuracy, I need to convert binarize predictions, which are given as probabilities\n",
    "# I will binarize by calling every probability >= 0.5 as 1, and everything <0.5 0\n",
    "predictions[predictions>=0.5] = 1\n",
    "predictions[predictions<0.5] = 0\n",
    "predictions = predictions.astype(int)\n",
    "\n",
    "y_test = y_test.reshape(y_test.shape[0],1) #reshape to have compatible as predictions\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "test_accuracy = np.sum(predictions==y_test)/len(y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b9e0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(\n",
    "    fpr,\n",
    "    tpr,\n",
    "    color=\"darkorange\",\n",
    "    lw=lw\n",
    ")\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b73993",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "* Classifier had excellent performance, as seen through a nearly perfect ROC curve  and high accuracy on the held-out test set with balanced classes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
